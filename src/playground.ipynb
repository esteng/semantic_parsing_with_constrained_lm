{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_parsing_with_constrained_lm.scfg.scfg import SCFG\n",
    "from semantic_parsing_with_constrained_lm.scfg.generate import parse_and_render\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scfg = SCFG.from_file(\"/home/estengel/scratch/scfg_playground/pp.scfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_grammar = scfg.utterance_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_parsing_with_constrained_lm.scfg.parser.token import TerminalToken, NonterminalToken\n",
    "\n",
    "def expand(grammar, nonterminal):\n",
    "    return [x[0] for x in grammar[nonterminal]]\n",
    "\n",
    "def check_all_terminal(sequence):\n",
    "    if len(sequence) == 0:\n",
    "        return False\n",
    "    for s in sequence:\n",
    "        if not isinstance(s, TerminalToken):\n",
    "            return False\n",
    "    return True \n",
    "\n",
    "def generate(grammar, symbol, strings=[]): \n",
    "    \"\"\"Generate all possible strings from a lark CFG\n",
    "    \n",
    "    Args:\n",
    "        lark_grammar (lark.Lark): a lark grammar object\n",
    "    Returns:\n",
    "        list of str: all possible strings\n",
    "    \"\"\"\n",
    "    \n",
    "    def helper(grammar, symbol):\n",
    "        # case 1: symbol is terminal\n",
    "        if isinstance(symbol, TerminalToken):\n",
    "            # add to current string\n",
    "            return symbol.underlying\n",
    "            \n",
    "        # case 2: symbol is nonterminal\n",
    "        elif isinstance(symbol, NonterminalToken):\n",
    "            # expand and repeat \n",
    "            print(f\"expanding {symbol}\")\n",
    "            return [helper(grammar, x) for x in expand(grammar, symbol.underlying)]\n",
    "\n",
    "        elif isinstance(symbol, str):\n",
    "            return [helper(grammar, x) for x in expand(grammar, symbol)]\n",
    "        # case 3: expansion rule has created sequence of options \n",
    "        elif type(symbol) in [tuple,list]:\n",
    "            return [helper(grammar, tok) for tok in symbol]\n",
    "        else:\n",
    "\n",
    "            raise ValueError(f\"Invalid symbol type: {type(symbol)}\")\n",
    "\n",
    "    strings = helper(grammar, symbol)\n",
    "    return strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expanding Ambig_PP_sentence_\n",
      "[(NonterminalToken(underlying='NP_animate', optional=False), NonterminalToken(underlying='V_observe', optional=False), NonterminalToken(underlying='NP_animate', optional=False), NonterminalToken(underlying='PP_visual_instr', optional=False)), (NonterminalToken(underlying='NP_animate', optional=False), NonterminalToken(underlying='V_observe', optional=False), NonterminalToken(underlying='NP_PP_visual_instr', optional=False))]\n",
      "expanding NonterminalToken(underlying='NP_animate', optional=False)\n",
      "expanding NonterminalToken(underlying='V_observe', optional=False)\n",
      "expanding NonterminalToken(underlying='NP_animate', optional=False)\n",
      "expanding NonterminalToken(underlying='PP_visual_instr', optional=False)\n",
      "expanding NonterminalToken(underlying='NP_visual_instr', optional=False)\n",
      "expanding NonterminalToken(underlying='NP_animate', optional=False)\n",
      "expanding NonterminalToken(underlying='V_observe', optional=False)\n",
      "expanding NonterminalToken(underlying='NP_PP_visual_instr', optional=False)\n",
      "expanding NonterminalToken(underlying='NP_animate', optional=False)\n",
      "expanding NonterminalToken(underlying='NP_visual_instr', optional=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "strings_to_sample = generate(string_grammar, 'Ambig_PP_sentence_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nest,  [[[['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], [['\" observed \"'], ['\" saw \"'], ['\" spotted \"']], [['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], [['\"with a \"', [['\"binoculars\"'], ['\"opera glasses\"'], ['\"a telescope\"']]]]], [[['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], [['\" observed \"'], ['\" saw \"'], ['\" spotted \"']], [[[['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], '\" with a \"', [['\"binoculars\"'], ['\"opera glasses\"'], ['\"a telescope\"']]]]]]\n",
      "Nest,  [[['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], [['\" observed \"'], ['\" saw \"'], ['\" spotted \"']], [['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], [['\"with a \"', [['\"binoculars\"'], ['\"opera glasses\"'], ['\"a telescope\"']]]]]\n",
      "Nest,  [['\"with a \"', [['\"binoculars\"'], ['\"opera glasses\"'], ['\"a telescope\"']]]]\n",
      "Nest,  [[['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], [['\" observed \"'], ['\" saw \"'], ['\" spotted \"']], [[[['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], '\" with a \"', [['\"binoculars\"'], ['\"opera glasses\"'], ['\"a telescope\"']]]]]\n",
      "Nest,  [[[['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], '\" with a \"', [['\"binoculars\"'], ['\"opera glasses\"'], ['\"a telescope\"']]]]\n",
      "Nest,  [[['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']], '\" with a \"', [['\"binoculars\"'], ['\"opera glasses\"'], ['\"a telescope\"']]]\n",
      "None\n",
      "['\"the boy\"', '\" observed \"', '\"Galileo\"', '\"with a \"', '\"the girl\"', '\" saw \"', '\"the man\"', '\"', '\"binoculars\"']\n"
     ]
    }
   ],
   "source": [
    "# TODO: take the produce of the nested lists here to sample \n",
    "\n",
    "class EnumSampler:\n",
    "    \"\"\"Sample everything that hasn't already been sampled\"\"\"\n",
    "    def __call__(self, s, done):\n",
    "        for x in s:\n",
    "            if x not in done:\n",
    "                return x\n",
    "        return None\n",
    "\n",
    "done = []\n",
    "\n",
    "def reduce_singleton(s):\n",
    "    if len(s) == 1:\n",
    "        return [s[0]]\n",
    "    lens = [len(x) for x in s]\n",
    "    types = [type(x[0]) for x in s]\n",
    "    if all([x == 1 for x in lens]) and all([x == str for x in types]):\n",
    "        return [x for l in s for x in l ]\n",
    "    return s \n",
    "\n",
    "sampled = []\n",
    "\n",
    "def sample(nested_strs, sampler):\n",
    "    # nested_strs is list of lists, where we can keep going down until we get to a terminal (str)\n",
    "    print(\"Nest, \", nested_strs)\n",
    "    for s in nested_strs:\n",
    "        if len(s) == 0:\n",
    "            return None \n",
    "        # reduce singleton lists \n",
    "        s = reduce_singleton(s)\n",
    "        if isinstance(s[0], str):\n",
    "            samp = sampler(s, done)\n",
    "            if samp is None:\n",
    "                return None\n",
    "            done.append(samp)\n",
    "            sampled.append(samp)\n",
    "        else:\n",
    "            sample(s, sampler) \n",
    "\n",
    "\n",
    "\n",
    "print(sample(strings_to_sample, EnumSampler()))\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1] [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\"the boy\"', '\"Galileo\"', '\"the girl\"', '\"the man\"']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_singleton([['\"the boy\"'], ['\"Galileo\"'], ['\"the girl\"'], ['\"the man\"']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_generate(grammar, start_symbol):\n",
    "\n",
    "\n",
    "    discovered = []\n",
    "    nodes_list = []\n",
    "    def dfs_helper(grammar, node):\n",
    "        discovered.append(node)\n",
    "        if isinstance(node, TerminalToken):\n",
    "            nodes_list.append(node.underlying)\n",
    "\n",
    "        elif isinstance(node, NonterminalToken):\n",
    "            name = node.underlying\n",
    "            expansions = expand(grammar, name)\n",
    "            for expansion_tuple in expansions:\n",
    "                for expansion_node in expansion_tuple:\n",
    "                    if expansion_node not in discovered:\n",
    "                        dfs_helper(grammar, expansion_node)\n",
    "\n",
    "        elif isinstance(node, str):\n",
    "            name = node\n",
    "            expansions = expand(grammar, name)\n",
    "            for expansion_tuple in expansions:\n",
    "                for expansion_node in expansion_tuple:\n",
    "                    if expansion_node not in discovered:\n",
    "                        dfs_helper(grammar, expansion_node)\n",
    "\n",
    "    dfs_helper(grammar, start_symbol)\n",
    "    return nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a telescope\"\n",
      "\"opera glasses\"\n",
      "\"binoculars\"\n",
      "\" with a \"\n",
      "\"the man\"\n",
      "\"the girl\"\n",
      "\"Galileo\"\n",
      "\"the boy\"\n",
      "\" spotted \"\n",
      "\" saw \"\n",
      "\" observed \"\n",
      "\"the man\"\n",
      "\"the girl\"\n",
      "\"Galileo\"\n",
      "\"the boy\"\n",
      "\"a telescope\"\n",
      "\"opera glasses\"\n",
      "\"binoculars\"\n",
      "\"with a \"\n",
      "\"the man\"\n",
      "\"the girl\"\n",
      "\"Galileo\"\n",
      "\"the boy\"\n",
      "\" spotted \"\n",
      "\" saw \"\n",
      "\" observed \"\n",
      "\"the man\"\n",
      "\"the girl\"\n",
      "\"Galileo\"\n",
      "\"the boy\"\n"
     ]
    }
   ],
   "source": [
    "def iter_dfs(grammar, start_symbol):\n",
    "    # frontier is a stack \n",
    "    frontier = []\n",
    "    frontier.append(start_symbol)\n",
    "    discovered = []\n",
    "    visited = []\n",
    "    while len(frontier) > 0:\n",
    "        s = frontier[-1]\n",
    "        frontier.pop()\n",
    "        if s not in discovered:\n",
    "            try:\n",
    "                discovered.append(s.underlying)\n",
    "            except AttributeError:\n",
    "                discovered.append(s)\n",
    "            if isinstance(s, TerminalToken):\n",
    "                print(s.underlying)\n",
    "            elif isinstance(s, NonterminalToken):\n",
    "                expansions = expand(grammar, s.underlying)\n",
    "                for expansion_tuple in expansions:\n",
    "                    for expansion_node in expansion_tuple:\n",
    "                        frontier.append(expansion_node)\n",
    "            elif isinstance(s, str):\n",
    "                expansions = expand(grammar, s)\n",
    "                for expansion_tuple in expansions:\n",
    "                    for expansion_node in expansion_tuple:\n",
    "                        frontier.append(expansion_node)\n",
    "\n",
    "iter_dfs(string_grammar, \"Ambig_PP_sentence_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('bclamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5838cd6d3aa9395e77de8eb86a5b18574c2a5a3b61b7b1f2baa99b5eb005498"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
